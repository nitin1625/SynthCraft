{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7344713,"sourceType":"datasetVersion","datasetId":4264820}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. Import Stuff","metadata":{}},{"cell_type":"code","source":"# !pip install tensorflow tensorflow-gpu matplotlib tensorflow-datasets ipywidgets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ngpus=tf.config.experimental.list_physical_devices('GPU')\nfor gpu in gpus:\n    tf.config.experimental.set_memory_growth(gpu,True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import tensorflow datasets for fashion mnist\nimport tensorflow_datasets as tfds\nfrom matplotlib import pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds=tfds.load('fashion_mnist',split='train')","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds.as_numpy_iterator().next().keys()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Visulaize Data\n","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"import numpy as np ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataiterator=ds.as_numpy_iterator()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting data out of pipeline\ndataiterator.next()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,ax=plt.subplots(ncols=4,figsize=(20,20))\nfor idx in range(4):\n    sample=dataiterator.next()  # grab an image and label\n    ax[idx].imshow(np.squeeze(sample['image']))\n    ax[idx].title.set_text(sample['label'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.squeeze(dataiterator.next()['image']).shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scale and return images only\ndef scale_images(data):\n    image=data['image']\n    return image/255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nsteps in data pipeline :-\n    map\n    cache\n    shuffle\n    batch\n    prefetch\n    \n    '''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds=tfds.load('fashion_mnist',split='train')  # reload data\nds=ds.map(scale_images) # map scale_images function on dataset\nds=ds.cache() # cache the dataset for that batch\nds=ds.shuffle(60000) # shuffle the data\nds=ds.batch(128) # batch into 128 images per sample\nds=ds.prefetch(64)  # store 64 images in cache","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds.as_numpy_iterator().next().shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Build Neural Network","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential  # contain Gens and Degens\nfrom tensorflow.keras.layers import Conv2D,Dense,Flatten,Reshape,LeakyReLU,Dropout,UpSampling2D","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.1 Build Generator","metadata":{}},{"cell_type":"code","source":"def build_generator():\n    \n    # takes in random values and reshapes it to 7*7*128\n    # Beginnings of a generated image\n    model=Sequential()\n    model.add(Dense(7*7*128,input_dim=128)) # 7*7 is random value\n    model.add(LeakyReLU(0.2))\n    model.add(Reshape((7,7,128)))\n    \n    # upsampling block 1\n    model.add(UpSampling2D())\n    model.add(Conv2D(128,5,padding='same'))\n    model.add(LeakyReLU(0.2))\n    \n     # upsampling block 2\n    model.add(UpSampling2D())\n    model.add(Conv2D(128,5,padding='same'))\n    model.add(LeakyReLU(0.2))\n    \n     # Conv block 1\n    model.add(Conv2D(128,4,padding='same'))\n    model.add(LeakyReLU(0.2))\n    \n    # Conv block 2\n    model.add(Conv2D(128,4,padding='same'))\n    model.add(LeakyReLU(0.2))\n    \n    # Conv layer to get one channel\n    model.add(Conv2D(1,4,padding='same',activation='sigmoid'))\n    \n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator=build_generator()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img=generator.predict(np.random.randn(4,128,1)) # generate 4 random images with 128 random values\nImg=img\nfig,ax=plt.subplots(ncols=4,figsize=(20,20))\nfor idx,img in enumerate(img) :\n    ax[idx].imshow(np.squeeze(img))\n    ax[idx].title.set_text(idx)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2 Build Discriminator","metadata":{}},{"cell_type":"code","source":"def build_discriminator():\n    model=Sequential()\n    \n    # first Conv Block\n    model.add(Conv2D(32,5,input_shape=(28,28,1)))\n    model.add(LeakyReLU(0.2))\n    model.add(Dropout(0.4))\n    \n    # second Conv Block\n    model.add(Conv2D(64,5))\n    model.add(LeakyReLU(0.2))\n    model.add(Dropout(0.4))\n    \n     # Third Conv Block\n    model.add(Conv2D(128,5))\n    model.add(LeakyReLU(0.2))\n    model.add(Dropout(0.4))\n    \n     # Fourth Conv Block\n    model.add(Conv2D(256,5))\n    model.add(LeakyReLU(0.2))\n    model.add(Dropout(0.4))\n    \n    # flatten then pass to dense layer\n    model.add(Flatten())\n    model.add(Dropout(0.4))\n    model.add(Dense(1,activation='sigmoid'))\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator=build_discriminator()\ndiscriminator.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Img","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img=Img[0]\nimg.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator.predict(np.expand_dims(img,0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Training Loop","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import BinaryCrossentropy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g_opt=Adam(learning_rate=0.0001)\nd_opt=Adam(learning_rate=0.00001)\ng_loss=BinaryCrossentropy()\nd_loss=BinaryCrossentropy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from  tensorflow.keras.models import Model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FashionGAN(Model): \n    def __init__(self, generator, discriminator, *args, **kwargs):\n        # Pass through args and kwargs to base class \n        super().__init__(*args, **kwargs)\n        \n        # Create attributes for gen and disc\n        self.generator = generator \n        self.discriminator = discriminator \n        \n    def compile(self, g_opt, d_opt, g_loss, d_loss, *args, **kwargs): \n        # Compile with base class\n        super().compile(*args, **kwargs)\n        \n        # Create attributes for losses and optimizers\n        self.g_opt = g_opt\n        self.d_opt = d_opt\n        self.g_loss = g_loss\n        self.d_loss = d_loss \n\n    def train_step(self, batch):\n        # Get the data \n        real_images = batch\n        fake_images = self.generator(tf.random.normal((128, 128, 1)), training=False)\n        \n        # Train the discriminator\n        with tf.GradientTape() as d_tape: \n            # Pass the real and fake images to the discriminator model\n            yhat_real = self.discriminator(real_images, training=True) \n            yhat_fake = self.discriminator(fake_images, training=True)\n            yhat_realfake = tf.concat([yhat_real, yhat_fake], axis=0)\n            \n            # Create labels for real and fakes images\n            y_realfake = tf.concat([tf.zeros_like(yhat_real), tf.ones_like(yhat_fake)], axis=0)\n            \n            # Add some noise to the TRUE outputs\n            noise_real = 0.15*tf.random.uniform(tf.shape(yhat_real))\n            noise_fake = -0.15*tf.random.uniform(tf.shape(yhat_fake))\n            y_realfake += tf.concat([noise_real, noise_fake], axis=0)\n            \n            # Calculate loss - BINARYCROSS \n            total_d_loss = self.d_loss(y_realfake, yhat_realfake)\n            \n        # Apply backpropagation - nn learn \n        dgrad = d_tape.gradient(total_d_loss, self.discriminator.trainable_variables) \n        self.d_opt.apply_gradients(zip(dgrad, self.discriminator.trainable_variables))\n        \n        # Train the generator \n        with tf.GradientTape() as g_tape: \n            # Generate some new images\n            gen_images = self.generator(tf.random.normal((128,128,1)), training=True)\n                                        \n            # Create the predicted labels\n            predicted_labels = self.discriminator(gen_images, training=False)\n                                        \n            # Calculate loss - trick to training to fake out the discriminator\n            total_g_loss = self.g_loss(tf.zeros_like(predicted_labels), predicted_labels) \n            \n        # Apply backprop\n        ggrad = g_tape.gradient(total_g_loss, self.generator.trainable_variables)\n        self.g_opt.apply_gradients(zip(ggrad, self.generator.trainable_variables))\n        \n        return {\"d_loss\":total_d_loss, \"g_loss\":total_g_loss}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create instance of subclassed model\nfashgan = FashionGAN(generator, discriminator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile the model\nfashgan.compile(g_opt, d_opt, g_loss, d_loss)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom tensorflow.keras.preprocessing.image import array_to_img\nfrom tensorflow.keras.callbacks import Callback","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.1 Build Callback","metadata":{}},{"cell_type":"code","source":"      # Create a directory if it is not there, so we can save files and results in it\n      from pathlib import Path\n      Path('/kaggle/working/main_folder/sub_folder').mkdir(parents=True, exist_ok=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ModelMonitor(Callback):\n    def __init__(self, num_img=3, latent_dim=128):\n        self.num_img = num_img\n        self.latent_dim = latent_dim\n\n    def on_epoch_end(self, epoch, logs=None):\n        random_latent_vectors = tf.random.uniform((self.num_img, self.latent_dim,1))\n        generated_images = self.model.generator(random_latent_vectors)\n        generated_images *= 255\n        generated_images.numpy()\n        for i in range(self.num_img):\n            img = array_to_img(generated_images[i])\n            img.save(os.path.join('/kaggle/working/main_folder/sub_folder', f'generated_img_{epoch}_{i}.png'))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Train","metadata":{}},{"cell_type":"code","source":"# Recommend 2000 epochs\nhist = fashgan.fit(ds, epochs=50, callbacks=[ModelMonitor()])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Review Performance","metadata":{}},{"cell_type":"code","source":"plt.suptitle('Loss')\nplt.plot(hist.history['d_loss'], label='d_loss')\nplt.plot(hist.history['g_loss'], label='g_loss')\nplt.legend()|\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7. Test Generator","metadata":{}},{"cell_type":"markdown","source":"### 7.1 Generate images","metadata":{}},{"cell_type":"code","source":"imgs = generator.predict(tf.random.normal((16, 128, 1)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(ncols=4, nrows=4, figsize=(10,10))\nfor r in range(4): \n    for c in range(4): \n        ax[r][c].imshow(imgs[(r+1)*(c+1)-1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7.2 Save the Model","metadata":{}},{"cell_type":"code","source":"generator.save('generator.h5')\ndiscriminator.save('discriminator.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}